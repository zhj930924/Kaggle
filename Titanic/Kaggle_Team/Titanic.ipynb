{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Arrays\n",
    "#### Let's review what our train.csv data looked like in python up to this point. Run the following to load the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "csv_file_object = csv.reader(open('./train.csv', 'rb')) \n",
    "header = csv_file_object.next() \n",
    "data=[] \n",
    "\n",
    "for row in csv_file_object:\n",
    "    data.append(row)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now type  print data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '0' '3' ..., '7.25' '' 'S']\n",
      " ['2' '1' '1' ..., '71.2833' 'C85' 'C']\n",
      " ['3' '1' '3' ..., '7.925' '' 'S']\n",
      " ..., \n",
      " ['889' '0' '3' ..., '23.45' '' 'S']\n",
      " ['890' '1' '1' ..., '30' 'C148' 'C']\n",
      " ['891' '0' '3' ..., '7.75' '' 'Q']]\n"
     ]
    }
   ],
   "source": [
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is familiar... an array of strings that the csv package was able to read.\n",
    "#### Look at the first 15 rows of the Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['22', '38', '26', '35', '35', '', '54', '2', '27', '14', '4', '58',\n",
       "       '20', '39', '14'], \n",
       "      dtype='|S82')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:15,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great, that command gives just the ages, and they are still stored as strings. What type of object is this whole column, though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0::,5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first thing we have to do is import the Pandas package. It turns out that Pandas has its own functions to read or write a .csv file, so we are no longer actually using the csv package in the commands below. Let's create a new object called 'df' for storing the pandas version of train.csv. (This means you can still refer to the original 'data' numpy array for the rest of this tutorial anytime you want to compare and contrast.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For .read_csv, always use header=0 when you know row 0 is the header row\n",
    "df = pd.read_csv('train.csv', header=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    male  34.5      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "2          894       2         Myles, Mr. Thomas Francis    male  62.0      0   \n",
       "\n",
       "   Parch  Ticket    Fare Cabin Embarked  \n",
       "0      0  330911  7.8292   NaN        Q  \n",
       "1      0  363272  7.0000   NaN        S  \n",
       "2      0  240276  9.6875   NaN        Q  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = pd.read_csv('test.csv', header=0)\n",
    "tst.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You notice it has column names, and it has the index of rows labelled down the side. (Note: you can also try  df.tail(3) and you can feed it any number of rows.) Now, compared to the original data array, what kind of object is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print type(df)  # What kind of object is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall that using the csv package before, every value was interpreted as a string. But how does Pandas interpret them using its own csv reader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas is able to infer numerical types whenever it can detect them. So we have values already stored as integers. When it detected the existing decimal points somewhere in Age and Fare, it converted those columns to float. There are two more very valuable commands to learn on a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There's a lot of useful info there! You can see immediately we have 891 entries (rows), and for most of the variables we have complete values (891 are non-null). But not for Age, or Cabin, or Embarked -- those have nulls somewhere. Now try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is also very useful: pandas has taken all of the numerical columns and quickly calculated the mean, std, minimum and maximum value. Convenient! But also a word of caution: we know there are a lot of missing values in Age, for example. How did pandas deal with that? It must have left out any nulls from the calculation. So if we start quoting the \"average age on the Titanic\" we need to caveat how we derived that number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One step in any data analysis is the data cleaning. Thankfully pandas makes things easier to filter, manipulate, drop out, fill in, transform and replace values inside the dataframe. Below we also learn the syntax that pandas allows for referring to specific columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencing and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "5     NaN\n",
       "6    54.0\n",
       "7     2.0\n",
       "8    27.0\n",
       "9    14.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'][0:10] # Let's acquire the first 10 rows of the Age column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "5     NaN\n",
       "6    54.0\n",
       "7     2.0\n",
       "8    27.0\n",
       "9    14.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Age[0:10] # And try this alternative syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].mean() # At this point, we'd really like to get than mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].median() # See if you can obtain the .median of Age as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next thing we'd like to do is look at more specific subsets of the dataframe. Again pandas makes this very convenient to write. Pass it a [ list ] of the columns desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Pclass   Age\n",
       "0    male       3  22.0\n",
       "1  female       1  38.0\n",
       "2  female       3  26.0\n",
       "3  female       1  35.0\n",
       "4    male       3  35.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ ['Sex', 'Pclass', 'Age'] ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering data is another important tool if we are investigating the data by hand. The .describe() command had indicated that the maximum age was 80. What do the older passengers look like in this data set? This is written by passing the criteria of df as a where clause into df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Wheadon, Mr. Edward H</td>\n",
       "      <td>male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 24579</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ostby, Mr. Engelhart Cornelius</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113509</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>B30</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldschmidt, Mr. George B</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17754</td>\n",
       "      <td>34.6542</td>\n",
       "      <td>A5</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Connors, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370369</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Van der hoef, Mr. Wyckoff</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111240</td>\n",
       "      <td>33.5000</td>\n",
       "      <td>B19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                            Name   Sex  \\\n",
       "33            34         0       2           Wheadon, Mr. Edward H  male   \n",
       "54            55         0       1  Ostby, Mr. Engelhart Cornelius  male   \n",
       "96            97         0       1       Goldschmidt, Mr. George B  male   \n",
       "116          117         0       3            Connors, Mr. Patrick  male   \n",
       "170          171         0       1       Van der hoef, Mr. Wyckoff  male   \n",
       "\n",
       "      Age  SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
       "33   66.0      0      0  C.A. 24579  10.5000   NaN        S  \n",
       "54   65.0      0      1      113509  61.9792   B30        C  \n",
       "96   71.0      0      0    PC 17754  34.6542    A5        C  \n",
       "116  70.5      0      0      370369   7.7500   NaN        Q  \n",
       "170  61.0      0      0      111240  33.5000   B19        S  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Age'] > 60].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you were most interested in the mix of the gender and Passenger class of these older people, you would want to combine the two skills you just learned and get only a few columns for the same where filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Pclass   Age  Survived\n",
       "33   male       2  66.0         0\n",
       "54   male       1  65.0         0\n",
       "96   male       1  71.0         0\n",
       "116  male       3  70.5         0\n",
       "170  male       1  61.0         0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Age'] > 60][['Sex', 'Pclass', 'Age', 'Survived']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From visual examination of all 22 cases, it seems they were mostly men, mostly(?) 1st class, and mostly perished.\n",
    "\n",
    "#### Now it's time to investigate all of those missing Age values, because we will need to address them in our model if we hope to use all the data for more advanced algorithms. To filter for missing values, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex  Pclass  Age\n",
       "5     male       3  NaN\n",
       "17    male       2  NaN\n",
       "19  female       3  NaN\n",
       "26    male       3  NaN\n",
       "28  female       3  NaN"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Age'].isnull()][['Sex', 'Pclass', 'Age']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here the only thing we did was print all 177 cases, but the same syntax can be used later if we take action on them.\n",
    "\n",
    "#### It will also be useful to combine multiple criteria (joined by the syntax &). To practice even more functionality in the same line of code, let's take a count of the males in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 122\n",
      "2 108\n",
      "3 347\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print i, len(df[ (df['Sex'] == 'male') & (df['Pclass'] == i) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we finish the initial investigation by hand, let's use one other convenience function of pandas to derive a histogram of any numerical column. The histogram function is really a shortcut to the more powerful features of the matplotlib/pylab packages, so let's be sure that's imported. Type the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHlFJREFUeJzt3X+Q5HV95/HnW36KOZgNKZYCwg6I4mrUARVRL/GbgPxI\nLmJVqvBXeU7I5aqCF0EvnrukKkv+OcErS7wQ/7DEncWSGDQ/wArKQrEf60yp6Mlm0V2QOhwWV3eM\nrnoxd3KLvO+P/vZO78zsfj/z7e55fz/N61HVxXy/0zP9pPu7n+l593S3uTsiIjK5nhMdICIi46WF\nXkRkwmmhFxGZcFroRUQmnBZ6EZEJp4VeRGTCNS70ZnabmS2Y2a6BfS83sy+b2UNm9qCZvXLgc5vN\n7DEz22Nml40rXERE8uTco98KXL5k3weBLe5+AbAF+G8AZvZi4GpgI3Al8FEzs9HliojIajUu9O7+\nJeDHS3Y/A5xSfzwF7Ks/fiPwaXd/2t3ngceAi0aTKiIibRzb8uveA9xrZh8CDHhtvf9M4MsD59tX\n7xMRkSBtH4z9I+A6dz+b3qL/idEliYjIKLW9R/9Od78OwN0/a2Yfr/fvA3514HxnsTjWOYyZ6UV2\nRERacPdVPfaZe4/e6lPfPjN7PYCZXUJvFg9wN/AWMzvezM4BzgMePEps509btmwJb1CnOkvuLKGx\npM42Gu/Rm9kdQAWcamZ76f2VzR8C/93MjgF+DvzHeuHebWZ3AruBg8C13rasI+bn56MTsqhztNQ5\nOiU0QjmdbTQu9O7+tiN86pUr7XT3DwAfGCbq2er006dZWHii9ddv27Zt6Ib16zewf//80N9HRLpD\nz4xtMDs7u2aX1VvkveVpxxBfu3ga5gdNjrW8PoehztEpoRHK6WzDoiYrZlb6VGfkes8ti75OrPUc\nUETGz8zwMT0Y+6yVUopOyJSiA7KUcn2qc3RKaIRyOtvQQi8iMuE0uukQjW5EpIlGNyIisowW+gbl\nzO1SdECWUq5PdY5OCY1QTmcbWuhFRCacZvQdohm9iDRpM6Nv+6JmMrFOIPq9YvTsXJHR0uimQTlz\nuzSi7/MUo3iG7TDP4B33s3NzlHK7l9BZQiOU09mGFnoRkQmnGX2HdGVG34UGHRsiK9Pf0YuIyDJa\n6BuUM7dL0QGZUnRAllJu9xI6S2iEcjrb0EIvIjLhGmf0ZnYb8O+ABXd/2cD+PwauBZ4G/sHdN9X7\nNwPX1Puvc/ftR/i+mtEvoRn9YoOODZGVjevv6LcCfwHcPnBBFfC7wEvd/Wkz+5V6/0bgamAjvTcG\nv9/MXqAVXUQkTuPoxt2/BPx4ye4/Am5y96fr8/yw3n8V8Gl3f9rd5+m9afhFo8tde+XM7VJ0QKYU\nHZCllNu9hM4SGqGczjbazuhfCPyGmX3FzHaY2Svq/WcCTw6cb1+9T0REgrR9CYRjgXXufrGZvQr4\nDHDuar/J7Ows09PTAExNTTEzM0NVVcDiT9dn2/ai/naVud3fl3v+I223vfzRbkffHv190cfDJGxX\nVdWpnqNt93Wlp3/dzc3NARxaL1cr6wlTZrYB+Fz/wVgzuwe42d2/WG8/BlwM/CGAu99U7/8CsMXd\nv7rC99Tofgk9GLvYoGNDZGXjfMKU1ae+vwd+q77QFwLHu/uPgLuBN5vZ8WZ2DnAe8OBqgrpm+T3t\nrkrRAZlSdECWUm73EjpLaIRyOttoHN2Y2R30fp8+1cz2AluATwBbzexheq+C9e8B3H23md0J7AYO\nAtfqbruISCy91k2HaHSz2KBjQ2Rleq0bERFZRgt9g3Lmdik6IFOKDshSyu1eQmcJjVBOZxta6EVE\nJpxm9B2iGf1ig44NkZVpRi8iIstooW9QztwuRQdkStEBWUq53UvoLKERyulsQwu9iMiE04y+QzSj\nX2zQsSGyMs3oRURkGS30DcqZ26XogEwpOiBLKbd7CZ0lNEI5nW1ooRcRmXCa0XeIZvSLDTo2RFam\nGb2IiCyjhb5BOXO7FB2QKUUHZCnldi+hs4RGKKezDS30IiITTjP6DtGMfrFBx4bIysYyozez28xs\nwcx2rfC5/2xmz5jZLw/s22xmj5nZHjO7bDUxIiIyejmjm63A5Ut3mtlZwBuAJwb2bQSuBjYCVwIf\ntd7d1GKVM7dL0QGZUnRAllJu9xI6S2iEcjrbaFzo3f1LwI9X+NSHgfct2XcV8Gl3f9rd54HHgIuG\njRQRkfayZvRmtgH4nLu/rN5+I1C5+3vN7DvAK9z9gJn9BfBld7+jPt/HgXvc/W9X+J6a0S+hGf1i\ng44NkZW1mdEf2+JCngvcQG9sM5TZ2Vmmp6cBmJqaYmZmhqqqgMVfo55t24v629Uab0dffm+7K7eH\ntrUdvZ1SYm5uDuDQerlq7t54AjYAu+qPfw3YDzwOfAc4CMwDpwGbgE0DX/cF4NVH+J5egh07dqzZ\nZQEO3vK0Y4ivHTwN0zCqzvhjYy1v92GU0FlCo3s5nfW/j6y1u3/K/Tt6q0+4+zfd/XR3P9fdzwG+\nC1zg7j8A7gbebGbHm9k5wHnAg+1+BImIyCg0zujN7A56v0+fCiwAW9x968DnHwde6e4H6u3NwB/Q\nu6d/nbtvP8L39abLfrbRjH6xQceGyMrazOj1hKkO0UK/2KBjQ2RlelGzMVj+IGlXpeiATCk6IEsp\nt3sJnSU0QjmdbWihFxGZcBrddIhGN4sNOjZEVqbRjYiILKOFvkE5c7sUHZApRQdkKeV2L6GzhEYo\np7MNLfQiIhNOM/oO0Yx+sUHHhsjKNKMXEZFltNA3KGdul6IDMqXogCyl3O4ldJbQCOV0tqGFXkRk\nwmlG3yGa0S826NgQWZlm9CIisowW+gblzO1SdECmFB2QpZTbvYTOEhqhnM42tNCLiEw4zeg7RDP6\nxQYdGyIr04xeRESWaVzozew2M1sws10D+z5oZnvMbKeZ/Y2ZnTzwuc1m9lj9+cvGFb5WypnbpeiA\nTCk6IEspt3sJnSU0QjmdbeTco98KXL5k33bgJe4+AzwGbAYwsxcDVwMbgSuBj1pvHiEiIkGyZvRm\ntgH4nLu/bIXPvQn4PXd/h5ltovcO5TfXn/s8cKO7f3WFr9OMfgnN6BcbdGyIrCxqRn8NcE/98ZnA\nkwOf21fvExGRIMcO88Vm9qfAQXf/qzZfPzs7y/T0NABTU1PMzMxQVRWwOC+L3u7vW8vL6+lvV5nb\ntwAzqzj/kbbbXv5qvn/VeP7o2/+WW27p5PEYfXy22V7aGt1zpO2dO3dy/fXXd6anv51SYm5uDuDQ\nerlq7t54AjYAu5bsmwX+EThhYN8m4P0D218AXn2E7+kl2LFjx5pdFuDgLU87hvjawdMwDaPqjD82\n1vJ2H0YJnSU0upfTWf/7yFq7+6fcGf00vRn9S+vtK4APAb/h7j8aON+LgU8Br6Y3srkPeIGvcCGa\n0S+nGX3ficBTwQ2wfv0G9u+fj84QOUybGX3j6MbM7qD3+/SpZrYX2ALcABwP3Ff/Uc1X3P1ad99t\nZncCu4GDwLVazWX1niL+hw0sLOgPxmQyND4Y6+5vc/cz3P0Edz/b3be6+wvcfYO7X1ifrh04/wfc\n/Tx33+ju28ebP37LZ+ddlaIDMqXogEwpOiBLCcdnCY1QTmcbemasiMiE02vddIhm9F1qAP09v3SR\nXutGRESW0ULfoJy5XYoOyJSiAzKl6IAsJRyfJTRCOZ1taKEXEZlwmtF3iGb0XWoAzeilizSjFxGR\nZbTQNyhnbpeiAzKl6IBMKTogSwnHZwmNUE5nG1roRUQmnGb0HaIZfZcaQDN66SLN6EVEZBkt9A3K\nmdul6IBMKTogU4oOyFLC8VlCI5TT2YYWehGRCacZfYdoRt+lBtCMXrpIM3oREVmmcaE3s9vMbMHM\ndg3sW2dm283sUTO718xOGfjcZjN7zMz2mNll4wpfK+XM7VJ0QKYUHZApRQdkKeH4LKERyulsI+ce\n/Vbg8iX7NgH3u/v5wAPAZjj0VoJXAxuBK4GPWv0WVCIiEiP3PWM30HvP2JfV248Ar3f3BTM7HUju\n/iIz20TvjWtvrs/3eeBGd//qCt9TM/olNKPvUgNoRi9dtJYz+tPcfQHA3fcDp9X7zwSeHDjfvnqf\niIgEGdWDsRN7t6ecuV2KDsiUogMypeiALCUcnyU0QjmdbRzb8usWzGz9wOjmB/X+fcCvDpzvrHrf\nimZnZ5mengZgamqKmZkZqqoCFq/06O2+tb68xYWmytzeucrzH2m77eV35fuPart/fdaf7cjxGH18\nTvL2zp07O9XT304pMTc3B3BovVyt3Bn9NL0Z/Uvr7ZuBA+5+s5m9H1jn7pvqB2M/Bbya3sjmPuAF\nKw3jNaNfTjP6LjWAZvTSRW1m9I336M3sDnp3c041s73AFuAm4DNmdg3wBL2/tMHdd5vZncBu4CBw\nrVZzEZFYjTN6d3+bu5/h7ie4+9nuvtXdf+zul7r7+e5+mbv/ZOD8H3D389x9o7tvH2/++JUzt0vR\nAZlSdECmFB2QpYTjs4RGKKezDT0zVkRkwum1bjpEM/ouNYBm9NJFeq0bERFZRgt9g3Lmdik6IFOK\nDsiUogOylHB8ltAI5XS2oYVeRGTCaUbfIZrRd6kBNKOXLtKMXkREltFC36CcuV2KDsiUogMypeiA\nLCUcnyU0QjmdbWihFxGZcJrRd4hm9F1qAM3opYs0oxcRkWW00DcoZ26XogMypeiATCk6IEsJx2cJ\njVBOZxta6EVEJpxm9B2iGX2XGkAzeukizehFRGQZLfQNypnbpeiATCk6IFOKDshSwvFZQiOU09nG\nUAu9mb3HzL5pZrvM7FNmdryZrTOz7Wb2qJnda2anjCpWRERWr/WM3szOAL4EvMjd/5+Z/TVwD/Bi\n4Efu/sHB95Nd4es1o19CM/ouNYBm9NJFETP6Y4DnmdmxwHOBfcBVwLb689uANw15GSIiMoTWC727\nfw/4ELCX3gL/U3e/H1jv7gv1efYDp40iNEo5c7sUHZApRQdkStEBWUo4PktohHI622i90JvZFL17\n7xuAM+jds387y3/n1u++IiKBjh3iay8FHnf3AwBm9nfAa4EFM1vv7gtmdjrwgyN9g9nZWaanpwGY\nmppiZmaGqqqAxZ+uz7btRf3tKnO7vy/3/Efabnv5k7Z9uK4cHyVuV1XVqZ6jbfd1pad/3c3NzQEc\nWi9Xa5gHYy8CbgNeBTwFbAW+BpwNHHD3m/Vg7OrowdguNYAejJUuWtMHY939QeCzwEPAP9H71/kx\n4GbgDWb2KHAJcFPby+iCcuZ2KTogU4oOyJSiA7KUcHyW0AjldLYxzOgGd/9z4M+X7D5Ab6wjIiId\noNe66RCNbrrUABrdSBfptW5ERGQZLfQNypnbpeiATCk6IFOKDshSwvFZQiOU09mGFnoRkQmnGX2H\naEbfpQbQjF66SDN6ERFZRgt9g3Lmdik6IFOKDsiUogOylHB8ltAI5XS2oYVeRGTCaUbfIZrRd6kB\n4ER6r+4RZ/36DezfPx/aIN3SZkavhb5DtNB3qQG60aEHhOVwejB2DMqZ26XogEwpOiBTig7IUsLx\nWUIjlNPZhhZ6EZEJp9FNh2h006UG6EaHRjdyOI1uRERkGS30DcqZ26XogEwpOiBTig7IUsLxWUIj\nlNPZhhZ6EZEJN9SM3sxOAT4O/BrwDHAN8G3gr+m9afg8cLW7/3SFr9WMfgnN6LvUAN3o0IxeDhcx\no/8IcI+7bwReDjwCbALud/fzgQeAzUNehoiIDKH1Qm9mJwO/7u5bAdz96fqe+1XAtvps24A3DV0Z\nqJy5XYoOyJSiAzKl6IAsJRyfJTRCOZ1tDHOP/hzgh2a21cy+YWYfM7OTgPXuvgDg7vuB00YRKiIi\n7Qzz5uDHAhcC73L3r5vZh+mNbZYOFI84YJydnWV6ehqAqakpZmZmqKoKWPzp+mzbXtTfrjK3+/ty\nz3+k7baXP2nbS0X11FsdOT7bbFdV1ameo233daWnf93Nzc0BHFovV6v1g7Fmth74srufW2//W3oL\n/fOByt0XzOx0YEc9w1/69Xowdgk9GNulBuhGhx6MlcOt6YOx9XjmSTN7Yb3rEuBbwN3AbL3vncBd\nbS+jC8qZ26XogEwpOiBTig7IUsLxWUIjlNPZxjCjG4B3A58ys+OAx4HfB44B7jSza4AngKuHvAwR\nERmCXuumQzS66VIDdKNDoxs5nF7rRkREltFC36CcuV2KDsiUogMypeiALCUcnyU0QjmdbQw7ox/K\nI488wnvfu4Xo30xf85pX8Gd/9l9iI0RExiR0Rn/rrbfynvfcxcGDfxDS0PND1q27iQMHngxs6NGM\nvksN0I0OzejlcG1m9KH36AGOOeYFHDz45sCCJ4GbAi9fRGS8NKNvUM7cLkUHZErRAZlSdECWEo7P\nEhqhnM42tNCLiEy48Bn9n/zJbn7+878Maeh5knXrXqsZ/WKFGg7pQodm9HI4/R29iIgso4W+QTlz\nuxQdkClFB2RK0QFZSjg+S2iEcjrb0EIvIjLhNKPXjH5phRoO6UKHZvRyOM3oRURkGS30wE9+cgAz\nCz8NJ43iqlgDKTogU4oOyFLCXLmERiins43wZ8Z2gfv/4ci/oieO/PZyozbsYi+T54QR3AkYzvr1\nG9i/fz60QYajhb5RFR2QqYoOyFRFB2SqogNqTxH9OMHCwnA/aPrvg9p1pXS2MfToxsyeY2bfMLO7\n6+11ZrbdzB41s3vN7JThM0VEpK1RzOivA3YPbG8C7nf384EHgM0juIxAKTogU4oOyJSiAzKl6IBM\nKTqgUSmz71I62xhqoTezs4DfBj4+sPsqYFv98TbgTcNchoiIDGfYe/QfBt7H4UPE9e6+AODu+4HT\nhryMYFV0QKYqOiBTFR2QqYoOyFRFBzQqZfZdSmcbrR+MNbPfARbcfaeZVUc56xEfSbr99ts5ePAZ\n4EZgCphh8cBN9X/Hvf38Nb68pm0aPj/pl9+1bRo+P+mX39vujzX6i6G21247pcTc3BwA09PTtOLu\nrU7AfwX2Ao8D3wd+BnwS2EPvXj3A6cCeI3y933rrrX7iidc6eOBprwNH+fyONWw5WkfTaVSdwzSM\nqnPcDbmdXehoahjV7X70hmHs2LFjqK9fK6V01rcHqzm1Ht24+w3ufra7nwu8BXjA3d8BfA6Yrc/2\nTuCutpchIiLDG8czY28C3mBmjwKXUPz79FXRAZmq6IBMVXRApio6IFMVHdColNl3KZ1tjOQJU+7+\nReCL9ccHgEtH8X1FRGR4eq2bRik6IFOKDsiUogMypeiATCk6oFEpf59eSmcbWuhFRCacFvpGVXRA\npio6IFMVHZCpig7IVEUHNCpl9l1KZxta6EVEJpwW+kYpOiBTig7IlKIDMqXogEwpOqBRKbPvUjrb\n0EIvIjLhtNA3qqIDMlXRAZmq6IBMVXRApio6oFEps+9SOtvQQi8iMuG00DdK0QGZUnRAphQdkClF\nB2RK0QGNSpl9l9LZhhZ6EZEJp4W+URUdkKmKDshURQdkqqIDMlXRAY1KmX2X0tmGFnoRkQmnhb5R\nig7IlKIDMqXogEwpOiBTig5oVMrsu5TONrTQi4hMOC30jarogExVdECmKjogUxUdkKmKDmhUyuy7\nlM42RvJ69CIyyU7AzKIjWL9+A/v3z0dnFKn1PXozO8vMHjCzb5nZw2b27nr/OjPbbmaPmtm9ZnbK\n6HIjpOiATCk6IFOKDsiUogMypTW4jKcAH+K0Y8iv750WFp4Y6/+lZvQrexp4r7u/BHgN8C4zexGw\nCbjf3c8HHgA2D58pIiJtDfPm4PvdfWf98c+APcBZwFXAtvps24A3DRsZq4oOyFRFB2SqogMyVdEB\nmarogAxVdECWSZ7Rj+TBWDObBmaArwDr3X0Bej8MgNNGcRkiItLO0A/GmtkvAZ8FrnP3n5mZLznL\n0u1Dbr/9dg4efAa4EZii97Oiqj+b6v+Oe/v5DZ/v71urHho+f6TtWxjN9df28lfz/asxfv9Rbd/C\n4aJ6mi6/vy+qL2d7aesw36/equfp/Xvho9jeuXMn119//di+f9vtlBJzc3MATE9P04q7tz7R+0Hx\nBXqLfH/fHnr36gFOB/Yc4Wv91ltv9RNPvNbBA09760d7jvT5HWvYcrSOptOoOodpGFXnuBtyO7vQ\n0dQwqtt9nLfHqBrxcdqxY8dYv/+o1NcDqzkNO7r5BLDb3T8ysO9uYLb++J3AXUNeRrAqOiBTFR2Q\nqYoOyFRFB2SqogMyVNEBWSZ5Rt96dGNmrwPeDjxsZg8BDtwA3AzcaWbXAE8AV48iVERE2hnmr27+\n0d2PcfcZd7/A3S909y+4+wF3v9Tdz3f3y9z9J6MMXnspOiBTig7IlKIDMqXogEwpOiBDig7Ior+j\nFxGRYmmhb1RFB2SqogMyVdEBmarogExVdECGKjogyyTP6LXQi4hMOC30jVJ0QKYUHZApRQdkStEB\nmVJ0QIYUHZBFM3oRESmWFvpGVXRApio6IFMVHZCpig7IVEUHZKiiA7JoRi8iIsXSQt8oRQdkStEB\nmVJ0QKYUHZApRQdkSNEBWTSjFxGRYumtBBtV0QGZquiATFV0QKYqOiBTFR2QoRrR94l/S8NS385Q\nC72IFKL/loZxFhbi3zu3DY1uGqXogEwpOiBTig7IlKIDMqXogAwpOiBTig4YGy30IiITTgt9oyo6\nIFMVHZCpig7IVEUHZKqiAzJU0QGZquiAsdFCLyIy4ca20JvZFWb2iJl928zeP67LGb8UHZApRQdk\nStEBmVJ0QKYUHZAhRQdkStEBYzOWhd7MngPcClwOvAR4q5m9aByXNX47owMyqXO01Dk6JTRCOZ2r\nN64/r7wIeMzdnwAws08DVwGPjOnyxqiUN8hS52ipc3RKaIS8zvi/5W9jXAv9mcCTA9vfpbf4i4gU\nLP5v+WH1P2hCnzB13HHHAf/AySfvDWtw/7/8y78c7Rzza1QyrPnogEzz0QGZ5qMDMs1HB2SYjw7I\nNB8dMDbmPvqfTmZ2MXCju19Rb28C3N1vHjhP9I9FEZEiufuq7taPa6E/BngUuAT4PvAg8FZ33zPy\nCxMRkaMay+jG3X9hZv8J2E7vL3tu0yIvIhJjLPfoRUSkO0KeGdvVJ1OZ2W1mtmBmuwb2rTOz7Wb2\nqJnda2anBDeeZWYPmNm3zOxhM3t3RztPMLOvmtlDdeeWLnb2mdlzzOwbZnZ3vd25TjObN7N/qq/T\nBzvceYqZfcbM9tTH6au71mlmL6yvx2/U//2pmb27g53vMbNvmtkuM/uUmR3fpnHNF/qOP5lqK72u\nQZuA+939fOABYPOaVx3uaeC97v4S4DXAu+rrr1Od7v4U8JvufgEwA1xpZhfRsc4B1wG7B7a72PkM\nULn7Be7e/3PlLnZ+BLjH3TcCL6f3/JlOdbr7t+vr8ULgFcC/An9HhzrN7Azgj4EL3f1l9Ebtb23V\n6O5regIuBj4/sL0JeP9adxylbwOwa2D7EWB9/fHpwCPRjUt6/x64tMudwEnA14FXdbETOAu4j96r\nWt3d1dsd+A5w6pJ9neoETgb+1wr7O9W5pO0y4H90rRM4A3gCWFcv8ne3/bceMbpZ6clUZwZ05DrN\n3RcA3H0/cFpwzyFmNk3v3vJX6N3wneqsxyEPAfuB+9z9a3SwE/gw8D4OfyZMFzsduM/MvmZm/6He\n17XOc4AfmtnWeizyMTM7ie51DnozcEf9cWc63f17wIeAvcA+4Kfufn+bRr165ep14tFrM/sl4LPA\nde7+M5Z3hXe6+zPeG92cBVxkZi+hY51m9jvAgrvv5OhPOQy/PoHXeW/U8Nv0Rna/TseuT3r3PC8E\n/rJu/Vd6v7V3rRMAMzsOeCPwmXpXZzrNbIreS8dsoHfv/nlm9vYVmhobIxb6fcDZA9tn1fu6asHM\n1gOY2enAD4J7MLNj6S3yn3T3u+rdnevsc/f/Te+lAa+ge52vA95oZo8DfwX8lpl9EtjfsU7c/fv1\nf/+Z3sjuIrp3fX4XeNLdv15v/w29hb9rnX1XAv/T3X9Yb3ep81LgcXc/4O6/oPcYwmvbNEYs9F8D\nzjOzDWZ2PPAWerOnrjAOv2d3NzBbf/xO4K6lXxDgE8Bud//IwL5OdZrZr/T/GsDMngu8AdhDxzrd\n/QZ3P9vdz6V3LD7g7u8APkeHOs3spPq3OMzsefTmyg/TvetzAXjSzF5Y77oE+BYd6xzwVno/4Pu6\n1LkXuNjMTjQzo3dd7qZNY9CDDFfQe+bsY8CmqAc7Vui6A/gevVcu2gv8Pr0HQu6ve7cDU8GNrwN+\nQe81VR8CvlFfn7/csc6X1m07gV3An9b7O9W5pPn1LD4Y26lOerPv/m3+cP/fTdc666aX07tDtxP4\nW+CUjnaeBPwz8G8G9nWqE9hC7w7SLmAbcFybRj1hSkRkwunBWBGRCaeFXkRkwmmhFxGZcFroRUQm\nnBZ6EZEJp4VeRGTCaaEXEZlwWuhFRCbc/wcS1Vc1a0TKwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc137438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as P\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "df['Age'].hist()\n",
    "P.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inside the parentheses of .hist(), you can also be more explicit about options of this function. Before you invoke it, you can also be explicit that you are dropping the missing values of Age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWs6D3sys5TzozcxazoPezKzl/j/ailEnTpFbegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf3a6a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Age'].dropna().hist(bins=16, range=(0,80), alpha = .5)\n",
    "P.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok now that we are comfortable with the syntax, we are ready to begin transforming the values in the dataframe into the shape we need for machine learning. First of all, it's hard to run analysis on the string values of \"male\" and \"female\". Let's practice transforming it in three ways -- twice for fun and once to make it useful. We'll store our transformation in a new column, so the original Sex isn't changed.\n",
    "\n",
    "#### In Pandas, adding a column is as easy as naming it and passing it new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Gender'] = 4\n",
    "tst['Gender'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show some .head() rows of the dataframe to see what we just accomplished. Well, now let's make it mean something that's actually derived from the Sex column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Gender'] = df['Sex'].map( lambda x: x[0].upper() )\n",
    "tst['Gender'] = tst['Sex'].map( lambda x: x[0].upper() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iambda x is an built-in function of python for generating an anonymous function in the moment, at runtime. Remember that x[0] of any string returns its first character.\n",
    "\n",
    "#### But of course what we really need is a binary integer for female and male, similar to the way Survived is stored. As a matter of consistency, let's also make Gender into values of 0 and 1's. We have a precedent of analyzing the women first in all of our previous arrays, so let's decide female = 0 and male = 1.  So, for real this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Gender'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "tst['Gender'] = tst['Sex'].map( {'female': 0, 'male': 1} ).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's time to deal with the missing values of Age, because most machine learning will need a complete set of values in that column to use it. By filling it in with guesses, we'll be introducing some noise into a model, but if we can keep our guesses reasonable, some of them should be close to the historical truth (whatever it was...), and the overall predictive power of Age might still make a better model than before.  We know the average [known] age of all passengers is 29.6991176 -- we could fill in the null values with that. But maybe the median would be better? (to reduce the influence of a few rare 70- and 80-year olds?) The Age histogram did seem positively skewed. These are the kind of decisions you make as you create your models in a Kaggle competition.\n",
    "\n",
    "#### For now let's decide to be more sophisticated, that we want to use the age that was typical in each passenger class. And decide that the median might be better. Let's build another reference table to calculate what each of these medians are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_ages = np.zeros((2,3))\n",
    "median_ages\n",
    "median_ages_test = np.zeros((2,3))\n",
    "median_ages_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And then populating the array,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 41.,  24.,  22.],\n",
       "       [ 42.,  28.,  24.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = df[(df['Gender'] == i) & \\\n",
    "                              (df['Pclass'] == j+1)]['Age'].dropna().median()\n",
    " \n",
    "median_ages\n",
    "\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages_test[i,j] = tst[(tst['Gender'] == i) & \\\n",
    "                              (tst['Pclass'] == j+1)]['Age'].dropna().median()\n",
    " \n",
    "median_ages_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could fill in the missing ages directly into the Age column. But to be extra cautious and not lose the state of the original data, a more formal way would be to create a new column, AgeFill, and even record which ones were originally null (and thus artificially guessed).\n",
    "\n",
    "#### Make a copy of Age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeFill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Gender  AgeFill  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q       1     34.5  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S       0     47.0  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q       1     62.0  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S       1     27.0  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S       0     22.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AgeFill'] = df['Age']\n",
    "\n",
    "df.head()\n",
    "\n",
    "tst['AgeFill'] = tst['Age']\n",
    "\n",
    "tst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look at just the rows with missing values, and limit it to the columns important to us right now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeFill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  Pclass  Age  AgeFill\n",
       "5        1       3  NaN      NaN\n",
       "17       1       2  NaN      NaN\n",
       "19       0       3  NaN      NaN\n",
       "26       1       3  NaN      NaN\n",
       "28       0       3  NaN      NaN\n",
       "29       1       3  NaN      NaN\n",
       "31       0       1  NaN      NaN\n",
       "32       0       3  NaN      NaN\n",
       "36       1       3  NaN      NaN\n",
       "42       1       3  NaN      NaN"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['Age'].isnull() ][['Gender','Pclass','Age','AgeFill']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use some code to fill in AgeFill based on our median_ages table. Here we happen to use the alternate syntax for referring to an existing column, like df.Age rather than df['Age'].  There's a where clause on df and referencing its column AgeFill, then assigning it an appropriate value out of median_ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        df.loc[ (df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1),\\\n",
    "                'AgeFill'] = median_ages[i,j]\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        tst.loc[ (tst.Age.isnull()) & (tst.Gender == i) & (tst.Pclass == j+1),\\\n",
    "                'AgeFill'] = median_ages_test[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the exact same 10 rows we just looked at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeFill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  Pclass  Age  AgeFill\n",
       "5        1       3  NaN     25.0\n",
       "17       1       2  NaN     30.0\n",
       "19       0       3  NaN     21.5\n",
       "26       1       3  NaN     25.0\n",
       "28       0       3  NaN     21.5\n",
       "29       1       3  NaN     25.0\n",
       "31       0       1  NaN     35.0\n",
       "32       0       3  NaN     21.5\n",
       "36       1       3  NaN     25.0\n",
       "42       1       3  NaN     25.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['Age'].isnull() ][['Gender','Pclass','Age','AgeFill']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This confirms we accomplished exactly what we wanted.\n",
    "\n",
    "#### Let's also create a feature that records whether the Age was originally missing. This is relatively simple by allowing pandas to use the integer conversion of the True/False evaluation of its built-in function, pandas.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['AgeIsNull'] = pd.isnull(df.Age).astype(int)\n",
    "tst['AgeIsNull'] = pd.isnull(tst.Age).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have 3 new numerical columns, Gender, AgeFill, AgeIsNull... perhaps you want to run df.describe() to see the summary statistics of the whole dataframe again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a couple of other features, this time using simple math on existing columns. Since we know that Parch is the number of parents or children onboard, and SibSp is the number of siblings or spouses, we could collect those together as a FamilySize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "tst['FamilySize'] = tst['SibSp'] + tst['Parch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also create artificial features if we think it may be advantageous to a machine learning algorithm -- of course, it might not. For example, we know Pclass had a large effect on survival, and it's possible Age will too. One artificial feature could incorporate whatever predictive power might be available from both Age and Pclass by multiplying them. This amplifies 3rd class (3 is a higher multiplier) at the same time it amplifies older ages. Both of these were less likely to survive, so in theory this could be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Age*Class'] = df.AgeFill * df.Pclass\n",
    "tst['Age*Class'] = tst.AgeFill * tst.Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could make some histograms of our new columns to understand them better. Go back and find the .hist() commands above.\n",
    "\n",
    "#### We know we'd like to have better predictive power for the men, so you might be wishing you could pull out more information from the Name column -- for example the honorary or pedestrian title of the men? We won't accomplish that in this tutorial, but you may find ideas in the Kaggle forums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have our data almost ready for machine learning. But most basic ML techniques will not work on strings, and in python they almost always require the data to be an array-- the implementations we will see in the sklearn package are not written to use a pandas dataframe. So the last two things we need to do are (1) determine what columns we have left which are not numeric, and (2) send our pandas.DataFrame back to a numpy.array.\n",
    "\n",
    "#### In pandas you could always see the column types from the .info() method. You can also see them directly: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "Gender           int32\n",
       "AgeFill        float64\n",
       "AgeIsNull        int32\n",
       "FamilySize       int64\n",
       "Age*Class      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With a little manipulation, we can require .dtypes to show only the columns which are 'object', which for pandas means it has strings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.dtypes[df.dtypes.map(lambda x: x=='object')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (You may already have already transformed 'Embarked' in your own work above.)\n",
    "\n",
    "#### The next step is to drop the columns which we will not use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1) \n",
    "tst = tst.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also drop 'Age' even though it is numeric, since we copied and filled that to a better column AgeFill. The original 'Age' still has the missing values which won't work well in our future model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Age'], axis=1)\n",
    "tst = tst.drop(['Age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An alternate command is to drop any rows which still have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "tst_clean = imp.fit_transform(tst)\n",
    "df_clean = imp.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But remember that .dropna() removes an observation from df even if it only has 1 NaN, anywhere, in any of its columns. It could delete most of your dataset if you aren't careful with the state of missing values in other columns!\n",
    "\n",
    "#### Now we have a clean and tidy dataset that is ready for analysis.\n",
    "\n",
    "#### The final step is to convert it into a Numpy array. Pandas can always send back an array using the .values method. Assign to a new variable, train_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>AgeIsNull</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  SibSp  Parch     Fare  Gender  AgeFill  AgeIsNull  \\\n",
       "0        892.0     3.0    0.0    0.0   7.8292     1.0     34.5        0.0   \n",
       "1        893.0     3.0    1.0    0.0   7.0000     0.0     47.0        0.0   \n",
       "2        894.0     2.0    0.0    0.0   9.6875     1.0     62.0        0.0   \n",
       "3        895.0     3.0    0.0    0.0   8.6625     1.0     27.0        0.0   \n",
       "4        896.0     3.0    1.0    1.0  12.2875     0.0     22.0        0.0   \n",
       "\n",
       "   FamilySize  Age*Class  \n",
       "0         0.0      103.5  \n",
       "1         1.0      141.0  \n",
       "2         0.0      124.0  \n",
       "3         0.0       81.0  \n",
       "4         2.0       66.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = df_clean\n",
    "test_true = tst_clean\n",
    "colnames = list(df.columns.values)\n",
    "full_data = pd.DataFrame(full_data, columns = colnames)\n",
    "colnames_test = colnames.remove('Survived')\n",
    "X_test_true = pd.DataFrame(test_true, columns = colnames)\n",
    "full_data.head()\n",
    "X_test_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a sample of the RMS Titanic data, we can see the various features present for each passenger on the ship:\n",
    "- **Survived**: Outcome of survival (0 = No; 1 = Yes)\n",
    "- **Pclass**: Socio-economic class (1 = Upper class; 2 = Middle class; 3 = Lower class)\n",
    "- **Name**: Name of passenger\n",
    "- **Sex**: Sex of the passenger\n",
    "- **Age**: Age of the passenger (Some entries contain `NaN`)\n",
    "- **SibSp**: Number of siblings and spouses of the passenger aboard\n",
    "- **Parch**: Number of parents and children of the passenger aboard\n",
    "- **Ticket**: Ticket number of the passenger\n",
    "- **Fare**: Fare paid by the passenger\n",
    "- **Cabin** Cabin number of the passenger (Some entries contain `NaN`)\n",
    "- **Embarked**: Port of embarkation of the passenger (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "Since we're interested in the outcome of survival for each passenger or crew member, we can remove the **Survived** feature from this dataset and store it as its own separate variable `outcomes`. We will use these outcomes as our prediction targets.  \n",
    "Run the code block cell to remove **Survived** as a feature of the dataset and store it in `outcomes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>AgeIsNull</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  SibSp  Parch     Fare  Gender  AgeFill  AgeIsNull  \\\n",
       "0          1.0     3.0    1.0    0.0   7.2500     1.0     22.0        0.0   \n",
       "1          2.0     1.0    1.0    0.0  71.2833     0.0     38.0        0.0   \n",
       "2          3.0     3.0    0.0    0.0   7.9250     0.0     26.0        0.0   \n",
       "3          4.0     1.0    1.0    0.0  53.1000     0.0     35.0        0.0   \n",
       "4          5.0     3.0    0.0    0.0   8.0500     1.0     35.0        0.0   \n",
       "\n",
       "   FamilySize  Age*Class  \n",
       "0         1.0       66.0  \n",
       "1         1.0       38.0  \n",
       "2         0.0       78.0  \n",
       "3         1.0       35.0  \n",
       "4         0.0      105.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store the 'Survived' feature in a new variable and remove it from the dataset\n",
    "outcomes = full_data['Survived']\n",
    "data = full_data.drop('Survived', axis = 1)\n",
    "\n",
    "# Show the new dataset with 'Survived' removed\n",
    "display(data.head())\n",
    "\n",
    "# Create template for test output\n",
    "test_output_temp = X_test_true.drop(['Pclass', 'SibSp', 'Parch', 'Fare', 'Gender', 'AgeFill',\n",
    "       'AgeIsNull', 'FamilySize', 'Age*Class'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>AgeIsNull</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  SibSp  Parch     Fare  Gender  AgeFill  AgeIsNull  \\\n",
       "0        892.0     3.0    0.0    0.0   7.8292     1.0     34.5        0.0   \n",
       "1        893.0     3.0    1.0    0.0   7.0000     0.0     47.0        0.0   \n",
       "2        894.0     2.0    0.0    0.0   9.6875     1.0     62.0        0.0   \n",
       "3        895.0     3.0    0.0    0.0   8.6625     1.0     27.0        0.0   \n",
       "4        896.0     3.0    1.0    1.0  12.2875     0.0     22.0        0.0   \n",
       "\n",
       "   FamilySize  Age*Class  \n",
       "0         0.0      103.5  \n",
       "1         1.0      141.0  \n",
       "2         0.0      124.0  \n",
       "3         0.0       81.0  \n",
       "4         2.0       66.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test_true.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the training set (712, 10)\n",
      "Dimension of the test set (179, 10)\n",
      "Dimension of the true test set (418L, 10L)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, outcomes, test_size=0.2, random_state=2016)\n",
    "print 'Dimension of the training set', X_train.shape\n",
    "print 'Dimension of the test set', X_test.shape\n",
    "print 'Dimension of the true test set', test_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started With Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the random forest package\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# Create the random forest object which will include all the parameters\n",
    "# for the fit\n",
    "clf_forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fit the training data to the Survived labels and create the decision trees\n",
    "forest = clf_forest.fit(X_train, y_train)\n",
    "\n",
    "# Take the same decision trees and run it on the test data\n",
    "y_pred = forest.predict(X_test)\n",
    "y_pred_true = forest.predict(X_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832402234637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model 1: KNN\n",
    "from sklearn import neighbors\n",
    "n_neighbors = 5\n",
    "clf_knn = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "\n",
    "# Model 2: SVC\n",
    "from sklearn import svm\n",
    "clf_svc = svm.SVC()\n",
    "\n",
    "# Model 3: Emsemble AdaBoosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_ada = AdaBoostClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n"
     ]
    }
   ],
   "source": [
    "# Fit KNN to training data\n",
    "train_classifier(clf_knn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.038\n"
     ]
    }
   ],
   "source": [
    "# Fit SVC to training data\n",
    "train_classifier(clf_svc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AdaBoostClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.880\n"
     ]
    }
   ],
   "source": [
    "# Fit Emsemble AbaBoosting to training data\n",
    "train_classifier(clf_ada, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on training set and compute accuracy score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n",
    "    return accuracy_score(target.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "Accuracy score for test set: 0.648044692737\n"
     ]
    }
   ],
   "source": [
    "train_knn_accuracy = predict_labels(clf_knn, X_train, y_train)\n",
    "print \"Accuracy score for test set: {}\".format(predict_labels(clf_knn, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.027\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for test set: 0.63687150838\n"
     ]
    }
   ],
   "source": [
    "train_svc_score = predict_labels(clf_svc, X_train, y_train)\n",
    "print \"Accuracy score for test set: {}\".format(predict_labels(clf_svc, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.077\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.046\n",
      "Accuracy score for test set: 0.793296089385\n"
     ]
    }
   ],
   "source": [
    "train_boosting_score = predict_labels(clf_ada, X_train, y_train)\n",
    "print \"Accuracy score for test set: {}\".format(predict_labels(clf_ada, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"------------------------------------------\"\n",
    "    print \"Training set size: {}\".format(len(X_train))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print \"Accuracy score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"Accuracy score for test set: {}\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training set of different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the training set at ratio of 85 (757, 10)\n",
      "Dimension of the test set at ratio of 85 (134, 10)\n",
      "\n",
      "Dimension of the training set at ratio of 90 (801, 10)\n",
      "Dimension of the test set at ratio of 90 (90, 10)\n",
      "\n",
      "Dimension of the training set at ratio of 75 (668, 10)\n",
      "Dimension of the test set at ratio of 75 (223, 10)\n",
      "\n",
      "Dimension of the training set at ratio of 70 (623, 10)\n",
      "Dimension of the test set at ratio of 70 (268, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train_85, X_test_85, y_train_85, y_test_85 = train_test_split(data, outcomes, train_size=0.85, random_state=2016)\n",
    "print 'Dimension of the training set at ratio of 85', X_train_85.shape\n",
    "print 'Dimension of the test set at ratio of 85', X_test_85.shape\n",
    "print\"\"\n",
    "\n",
    "X_train_90, X_test_90, y_train_90, y_test_90 = train_test_split(data, outcomes, train_size=0.90, random_state=2016)\n",
    "print 'Dimension of the training set at ratio of 90', X_train_90.shape\n",
    "print 'Dimension of the test set at ratio of 90', X_test_90.shape\n",
    "print\"\"\n",
    "\n",
    "X_train_75, X_test_75, y_train_75, y_test_75 = train_test_split(data, outcomes, train_size=0.75, random_state=2016)\n",
    "print 'Dimension of the training set at ratio of 75', X_train_75.shape\n",
    "print 'Dimension of the test set at ratio of 75', X_test_75.shape\n",
    "print\"\"\n",
    "\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(data, outcomes, train_size=0.70, random_state=2016)\n",
    "print 'Dimension of the training set at ratio of 70', X_train_70.shape\n",
    "print 'Dimension of the test set at ratio of 70', X_test_70.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 623\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "Accuracy score for test set: 0.664804469274\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 668\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.004\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "Accuracy score for test set: 0.653631284916\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 712\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "Accuracy score for test set: 0.648044692737\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 757\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "Accuracy score for test set: 0.731843575419\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 801\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "Accuracy score for test set: 0.804469273743\n"
     ]
    }
   ],
   "source": [
    "# Model 1: KNN\n",
    "train_predict(clf_knn, X_train_70, y_train_70, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_knn, X_train_75, y_train_75, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_knn, X_train, y_train, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_knn, X_train_85, y_train_85, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_knn, X_train_90, y_train_90, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 623\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.030\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.020\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.006\n",
      "Accuracy score for test set: 0.63687150838\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 668\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.039\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.026\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.006\n",
      "Accuracy score for test set: 0.63687150838\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 712\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.038\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.024\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.006\n",
      "Accuracy score for test set: 0.63687150838\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 757\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.039\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.032\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for test set: 0.72625698324\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 801\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.045\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.035\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for test set: 0.810055865922\n"
     ]
    }
   ],
   "source": [
    "# Model 2: SVC\n",
    "train_predict(clf_svc, X_train_70, y_train_70, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_svc, X_train_75, y_train_75, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_svc, X_train, y_train, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_svc, X_train_85, y_train_85, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_svc, X_train_90, y_train_90, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 623\n",
      "Training AdaBoostClassifier...\n",
      "Done!\n",
      "Training time (secs): 1.052\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.072\n",
      "Accuracy score for training set: 0.895666131621\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.052\n",
      "Accuracy score for test set: 0.815642458101\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 668\n",
      "Training AdaBoostClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.902\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.075\n",
      "Accuracy score for training set: 0.898203592814\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.050\n",
      "Accuracy score for test set: 0.793296089385\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 712\n",
      "Training AdaBoostClassifier...\n",
      "Done!\n",
      "Training time (secs): 1.038\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.074\n",
      "Accuracy score for training set: 0.891853932584\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.040\n",
      "Accuracy score for test set: 0.793296089385\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 757\n",
      "Training AdaBoostClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.961\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.077\n",
      "Accuracy score for training set: 0.895640686922\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.043\n",
      "Accuracy score for test set: 0.832402234637\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 801\n",
      "Training AdaBoostClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.900\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.070\n",
      "Accuracy score for training set: 0.89138576779\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.040\n",
      "Accuracy score for test set: 0.843575418994\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Emsemble AdaBoosting\n",
    "train_predict(clf_ada, X_train_70, y_train_70, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_ada, X_train_75, y_train_75, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_ada, X_train, y_train, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_ada, X_train_85, y_train_85, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_ada, X_train_90, y_train_90, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 623\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.210\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.011\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for test set: 0.837988826816\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 668\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.213\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.012\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for test set: 0.837988826816\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 712\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.194\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.013\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for test set: 0.837988826816\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 757\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.199\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.015\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for test set: 0.865921787709\n",
      "\n",
      "------------------------------------------\n",
      "Training set size: 801\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.221\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.013\n",
      "Accuracy score for training set: 1.0\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "Accuracy score for test set: 0.905027932961\n"
     ]
    }
   ],
   "source": [
    "# Model 4: Emsemble Random Forest\n",
    "train_predict(clf_forest, X_train_70, y_train_70, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_forest, X_train_75, y_train_75, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_forest, X_train, y_train, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_forest, X_train_85, y_train_85, X_test, y_test)\n",
    "print \"\"\n",
    "train_predict(clf_forest, X_train_90, y_train_90, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "best for 80 {'n_estimators': 500, 'criterion': 'gini'}\n",
      "best for 85 {'n_estimators': 100, 'criterion': 'gini'}\n",
      "best for 90 {'n_estimators': 500, 'criterion': 'gini'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.794 (+/-0.058) for {'n_estimators': 10, 'criterion': 'gini'}\n",
      "0.796 (+/-0.058) for {'n_estimators': 100, 'criterion': 'gini'}\n",
      "0.794 (+/-0.057) for {'n_estimators': 250, 'criterion': 'gini'}\n",
      "0.803 (+/-0.055) for {'n_estimators': 500, 'criterion': 'gini'}\n",
      "0.791 (+/-0.049) for {'n_estimators': 10, 'criterion': 'entropy'}\n",
      "0.801 (+/-0.058) for {'n_estimators': 100, 'criterion': 'entropy'}\n",
      "0.798 (+/-0.059) for {'n_estimators': 250, 'criterion': 'entropy'}\n",
      "0.801 (+/-0.056) for {'n_estimators': 500, 'criterion': 'entropy'}\n",
      "\n",
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.050\n",
      "0.837988826816\n",
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.009\n",
      "0.860335195531\n",
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.046\n",
      "0.899441340782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "# Gridsearch on Emsemble Random Forest\n",
    "tuned_parameters_rf = {'criterion':(\"gini\", \"entropy\"), \n",
    "                        'n_estimators':[10, 100, 250, 500]\n",
    "                        }\n",
    "# 'max_depth':[5, 10, 15, 20, 30] \n",
    "rf = RandomForestClassifier(random_state = 2016)\n",
    "\n",
    "rf_best = GridSearchCV(rf, tuned_parameters_rf, scoring=accuracy_scorer, cv = 5)\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "rf_best_85 = GridSearchCV(rf, tuned_parameters_rf, scoring=accuracy_scorer, cv = 5)\n",
    "rf_best_85.fit(X_train_85, y_train_85)\n",
    "\n",
    "rf_best_90 = GridSearchCV(rf, tuned_parameters_rf, scoring=accuracy_scorer, cv = 5)\n",
    "rf_best_90.fit(X_train_90, y_train_90)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print \"\"\n",
    "print \"best for 80\", rf_best.best_params_\n",
    "print \"best for 85\", rf_best_85.best_params_\n",
    "print \"best for 90\", rf_best_90.best_params_\n",
    "print \"\"\n",
    "print(\"Grid scores on development set:\")\n",
    "print \"\"\n",
    "for params, mean_score, scores in rf_best.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "    % (mean_score, scores.std() * 2, params))\n",
    "print \"\"\n",
    "print predict_labels(rf_best, X_test, y_test)\n",
    "print predict_labels(rf_best_85, X_test, y_test)\n",
    "print predict_labels(rf_best_90, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 50}\n",
      "{'n_estimators': 50}\n",
      "{'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.789 (+/-0.055) for {'n_estimators': 50}\n",
      "0.789 (+/-0.049) for {'n_estimators': 100}\n",
      "0.788 (+/-0.061) for {'n_estimators': 150}\n",
      "\n",
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "0.793296089385\n",
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "0.804469273743\n",
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "0.832402234637\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch on Emsemble Adaboost\n",
    "tuned_parameters_ada = {'n_estimators':[50, 100, 150]}\n",
    "ada = AdaBoostClassifier(random_state = 2016)\n",
    "\n",
    "ada_best = GridSearchCV(ada, tuned_parameters_ada, scoring=accuracy_scorer, cv = 5)\n",
    "ada_best.fit(X_train, y_train)\n",
    "\n",
    "ada_best_85 = GridSearchCV(ada, tuned_parameters_ada, scoring=accuracy_scorer, cv = 5)\n",
    "ada_best_85.fit(X_train_85, y_train_85)\n",
    "\n",
    "ada_best_90 = GridSearchCV(ada, tuned_parameters_ada, scoring=accuracy_scorer, cv = 5)\n",
    "ada_best_90.fit(X_train_90, y_train_90)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print \"\"\n",
    "print(ada_best.best_params_)\n",
    "print(ada_best_85.best_params_)\n",
    "print(ada_best_90.best_params_)\n",
    "print \"\"\n",
    "print(\"Grid scores on development set:\")\n",
    "print \"\"\n",
    "for params, mean_score, scores in ada_best.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "    % (mean_score, scores.std() * 2, params))\n",
    "print \"\"\n",
    "print predict_labels(ada_best, X_test, y_test)\n",
    "print predict_labels(ada_best_85, X_test, y_test)\n",
    "print predict_labels(ada_best_90, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gridsearch on SVM\n",
    "#tuned_parameters_svc = {'kernel':('rbf', 'sigmoid')}\n",
    "#svc = svm.SVC(random_state = 2016)\n",
    "\n",
    "# 'C':np.arange(1, 5, 0.5)\n",
    "\n",
    "#svc_best = GridSearchCV(svc, tuned_parameters_svc, scoring=accuracy_scorer, cv = 5)\n",
    "#svc_best.fit(X_train, y_train)\n",
    "\n",
    "#print(\"Best parameters set found on development set:\")\n",
    "#print \"\"\n",
    "#print(svc_best.best_params_)\n",
    "#print \"\"\n",
    "#print(\"Grid scores on development set:\")\n",
    "#print \"\"\n",
    "#for params, mean_score, scores in svc_best.grid_scores_:\n",
    "#    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#    % (mean_score, scores.std() * 2, params))\n",
    "#print \"\"\n",
    "#print predict_labels(svc_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId\n",
      "0        892.0\n",
      "1        893.0\n",
      "2        894.0\n",
      "3        895.0\n",
      "4        896.0\n"
     ]
    }
   ],
   "source": [
    "test_output_temp\n",
    "print test_output_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Build ada best output\n",
    "y_pred_true_ada_best_90 = ada_best_90.predict(X_test_true)\n",
    "y_pred_true_ada_best_90 = int32(y_pred_true_ada_best_90)\n",
    "\n",
    "# Build rf best output\n",
    "y_pred_true_rf_best_90 = rf_best_90.predict(X_test_true)\n",
    "y_pred_true_rf_best_90 = int32(y_pred_true_ada_best_90)\n",
    "\n",
    "# Buidling super \n",
    "great_rf = RandomForestClassifier(n_estimators = 500)\n",
    "super_classifier = AdaBoostClassifier(base_estimator = great_rf)\n",
    "super_classifier.fit(X_train_90, y_train_90)\n",
    "y_pred_true_super = super_classifier.predict(X_test_true)\n",
    "y_pred_true_super = int32(y_pred_true_super)\n",
    "\n",
    "print y_pred_true_ada_best_90\n",
    "print y_pred_true_rf_best_90\n",
    "print y_pred_true_super"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_output_temp['PassengerId'] = test_output_temp['PassengerId'].astype(int)\n",
    "test_output_temp['Survived'] = y_pred_true_ada_best_90\n",
    "test_output_temp.to_csv('ada_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_output_temp['Survived'] = y_pred_true_rf_best_90\n",
    "test_output_temp.to_csv('rf_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_output_temp['Survived'] = y_pred_true_super\n",
    "test_output_temp.to_csv('super_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
